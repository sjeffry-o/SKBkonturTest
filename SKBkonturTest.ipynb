{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "82651da4-e7da-4788-a559-b80f7f121ceb",
      "metadata": {
        "id": "82651da4-e7da-4788-a559-b80f7f121ceb"
      },
      "source": [
        "# Задача и данные\n",
        "Требуется разработать модель, которая будет способна различать заголовки реальных и выдуманных новостей.\n",
        "Наши данные - заголовки новостей, лейбл - является ли новость фейком <br>\n",
        "Задача: по заголовку определить является ли новость фейком <br>\n",
        "\n",
        "Первая часть: поиск с google search (лучшее по качеству) <br>\n",
        "Вторая часть: NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cc177b0-2af9-4115-beda-d3df63234f23",
      "metadata": {
        "id": "1cc177b0-2af9-4115-beda-d3df63234f23"
      },
      "outputs": [],
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install google\n",
        "!pip install tensorflow==1.15.2\n",
        "!pip install deeppavlov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c24e191-f216-4eed-96b8-f0713dbdce7a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1c24e191-f216-4eed-96b8-f0713dbdce7a",
        "outputId": "fc673638-ff5c-4900-caa8-5144ed208200"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  is_fake\n",
              "0  Москвичу Владимиру Клутину пришёл счёт за вмеш...        1\n",
              "1  Агент Кокорина назвал езду по встречке житейск...        0\n",
              "2  Госдума рассмотрит возможность введения секрет...        1\n",
              "3  ФАС заблокировала поставку скоростных трамваев...        0\n",
              "4  Против Навального завели дело о недоносительст...        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4161cd24-bc73-44bf-8f16-debda837f737\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Москвичу Владимиру Клутину пришёл счёт за вмеш...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Агент Кокорина назвал езду по встречке житейск...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Госдума рассмотрит возможность введения секрет...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ФАС заблокировала поставку скоростных трамваев...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Против Навального завели дело о недоносительст...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4161cd24-bc73-44bf-8f16-debda837f737')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4161cd24-bc73-44bf-8f16-debda837f737 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4161cd24-bc73-44bf-8f16-debda837f737');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('./dataset/train.tsv', delimiter='\\t')\n",
        "test_df = pd.read_csv('./dataset/test.tsv', delimiter='\\t')\n",
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad23855d-32f8-443c-a163-4b69309832f2",
      "metadata": {
        "id": "ad23855d-32f8-443c-a163-4b69309832f2"
      },
      "source": [
        "Возьмем новость фейк и не фейк и заметим, что по этим запросам находятся страницы в поиске. Взяв выборку примерно из 10 фейковых новостей можно увидеть что они взяты с сайта фейковых новостей panorama.pub <br>\n",
        "Предполагаю, что лучшая модель для решения задачи не включает в себя статистических языковых моделей, а делается простым поиском\n",
        "\n",
        "из интересных находок: \n",
        "* (xe-xe-xe) новость <br> Заголовок: Россияне обхитрили рост цен <br> URL: https://lenta.ru/news/2018/04/17/xe_xe_xe/ "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f69e7fa-c1f1-487d-a08c-27566e1dd6e7",
      "metadata": {
        "id": "6f69e7fa-c1f1-487d-a08c-27566e1dd6e7"
      },
      "source": [
        "## Поиск гугл\n",
        "Гугл дает ограничение по запросам, нужно выставлять искусственную задержку между запросами <br>\n",
        "Пока гугл не кинул ошибку Too many requests на найденных 53 тренировочных новостях F1 мера показала 1.0 <br>\n",
        "Этого достаточно чтобы утверждать, что эта модель будет или идеальной, или близка к идеальной <br>\n",
        "т.к. один из критериев оценки - F1 мера точности, я включу эту модель в финальное решение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e94bfff-7169-4289-a363-3898eac460ca",
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "9e94bfff-7169-4289-a363-3898eac460ca"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from googlesearch import search\n",
        "except ImportError:\n",
        "    print(\"No module named 'google' found\")\n",
        "from time import sleep\n",
        "\n",
        "# titles = train_df['title'].values\n",
        "titles = test_df['title'].values\n",
        "\n",
        "def searchPredict(titles, labels=[]):\n",
        "  for title in titles[len(labels):]:\n",
        "      query = title\n",
        "      # print(query)\n",
        "      for j in search(query, tld=\"co.in\", num=1, stop=10, pause=2):\n",
        "          if 'panorama' in j:\n",
        "              labels.append(1)\n",
        "          else:\n",
        "              labels.append(0)\n",
        "          # print(j, labels[-1])\n",
        "          sleep(1)\n",
        "          break\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes about 2 hours\n",
        "labels = searchPredict(titles, labels)"
      ],
      "metadata": {
        "id": "tB-WTgxORsd7"
      },
      "id": "tB-WTgxORsd7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6009a3c1-7740-47b9-8b38-5e7e2a14e67a",
      "metadata": {
        "id": "6009a3c1-7740-47b9-8b38-5e7e2a14e67a",
        "outputId": "2f7a5b82-5216-4fbc-9283-f7108825a4a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_df labels\n",
        "len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1906edb0-ca30-4ed6-8641-b05cd67ef010",
      "metadata": {
        "id": "1906edb0-ca30-4ed6-8641-b05cd67ef010",
        "outputId": "529733fa-80e1-4f0a-c3ec-b3e2a04c7c7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_df labels\n",
        "from sklearn.metrics import f1_score\n",
        "y_true = train_df['is_fake'].values[:len(labels)]\n",
        "y_pred = labels\n",
        "f1_score(y_true, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['is_fake'] = labels\n",
        "test_df.to_csv('./predictions.tsv', index=False, sep='\\t')"
      ],
      "metadata": {
        "id": "t5Wtx8ze1JGd"
      },
      "id": "t5Wtx8ze1JGd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b8f5ea00-8855-49ce-a46c-20c0c6afa055",
      "metadata": {
        "id": "b8f5ea00-8855-49ce-a46c-20c0c6afa055"
      },
      "source": [
        "## Статистические языковые модели\n",
        "Хорошо, мы смогли понять откуда данные и получить отличную F1 метрику, теперь интересная часть <br>\n",
        "Смогут ли современные языковые модели по заголовку понять, фейковая ли новость? <br>\n",
        "Посмотрев на данные своими глазами и попробовав решить эту задачу без помощи автоматики, могу сказать что я затрудняюсь сказать по заголовку новости фейк это или нет. <br>\n",
        "\n",
        "**В этой задаче важно иметь subword токенизацию, так как именованные сущности встречаются почти в каждом заголовке**<br>\n",
        "Считаю, что стоит попробовать такие подходы как: <br>\n",
        "1. Векторизация TF-IDF (или любая другая токен-векторизовалка) + MLP (самый слабый из трех, потому что скорее всего не хватит Term'ов для редких аббревиатур, условно \"ФННБ\" встретится один раз и будет мало веса добавлять к вектору)\n",
        "2. ELMO + classifier (хороший tradeoff качество/скорость)\n",
        "3. BERT (лучшее по качеству) <br>\n",
        "\n",
        "Считаю, что не стоит включать word2vec в исследование, т.к. корпус включает в себя примеры со многим кол-вом именованных существительных и все неизвестные имена и названия при токенизации w2v будут отмечены как *UNK*, а что в решении того, фейк новость или нет, это помешает<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb13c024-5995-4594-af57-7253bcc7ad53",
      "metadata": {
        "tags": [],
        "id": "bb13c024-5995-4594-af57-7253bcc7ad53"
      },
      "source": [
        "### Data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "711af009-a77d-493f-beda-cd6b21e643a2",
      "metadata": {
        "id": "711af009-a77d-493f-beda-cd6b21e643a2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    train_df['title'].tolist(), train_df['is_fake'].tolist(), test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8bd5401-356a-42dd-8cd7-d31a1c8981e9",
      "metadata": {
        "id": "d8bd5401-356a-42dd-8cd7-d31a1c8981e9"
      },
      "source": [
        "### TF-IDF + classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "424f3c87-497a-49cd-ac0b-81c0180f5254",
      "metadata": {
        "id": "424f3c87-497a-49cd-ac0b-81c0180f5254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ba911a-492a-4f4d-e0c0-c1625f2cd0e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('vect',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(...\n",
              "                ('clf',\n",
              "                 SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
              "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
              "                               fit_intercept=True, l1_ratio=0.15,\n",
              "                               learning_rate='optimal', loss='hinge',\n",
              "                               max_iter=5, n_iter_no_change=5, n_jobs=None,\n",
              "                               penalty='l2', power_t=0.5, random_state=42,\n",
              "                               shuffle=True, tol=None, validation_fraction=0.1,\n",
              "                               verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "text_clf = Pipeline([\n",
        "    ('vect', TfidfVectorizer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None)),\n",
        "])\n",
        "\n",
        "text_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predicted = text_clf.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjMHwUl2XGTP",
        "outputId": "44a2fb2f-7013-4b53-a71d-a19f65dce0e3"
      },
      "id": "sjMHwUl2XGTP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21.2 ms, sys: 0 ns, total: 21.2 ms\n",
            "Wall time: 23.2 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd812f89-7181-4db0-bdd6-9eedece723d4",
      "metadata": {
        "id": "bd812f89-7181-4db0-bdd6-9eedece723d4",
        "outputId": "cb8dd89b-a761-4fb7-c4a0-5dff59086fd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7819391183357655"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = y_test\n",
        "y_pred = predicted\n",
        "f1_score(y_true, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4353824-8df0-4048-9976-d95a6334083e",
      "metadata": {
        "id": "d4353824-8df0-4048-9976-d95a6334083e"
      },
      "source": [
        "### ELMO (WMT news)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deeppavlov.models.embedders.elmo_embedder import ELMoEmbedder\n",
        "elmo = ELMoEmbedder(\"http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-news_wmt11-16_1.5M_steps.tar.gz\")"
      ],
      "metadata": {
        "id": "oAU60FW5E4ti"
      },
      "id": "oAU60FW5E4ti",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_splitted = [title.split() for title in X_train]\n",
        "val_splitted = [title.split() for title in X_test]"
      ],
      "metadata": {
        "id": "Y5HPmyCnjhLP"
      },
      "id": "Y5HPmyCnjhLP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "val_vectorized = elmo(val_splitted)\n",
        "print('valid data vectorization done')\n",
        "train_vectorized = elmo(train_splitted)\n",
        "print('train data vectorization done')\n",
        "\n",
        "with open('./train_vectors.pickle', 'wb') as f:\n",
        "    pickle.dump(train_vectorized, f)\n",
        "with open('./valid_vectors.pickle', 'wb') as f:\n",
        "    pickle.dump(val_vectorized, f)\n",
        "\n",
        "# Если подгрузили вектора ELMO\n",
        "# with open('./train_vectors.pickle', 'rb') as f:\n",
        "#     train_vectorized = pickle.load(f)\n",
        "# with open('./valid_vectors.pickle', 'rb') as f:\n",
        "#     val_vectorized   = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrYJ1S2VjztS",
        "outputId": "47ee8e54-ec28-451d-a472-d136969427a6"
      },
      "id": "TrYJ1S2VjztS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid data vectorization done\n",
            "train data vectorization done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP_clf(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "elmo_clf = MLP_clf()"
      ],
      "metadata": {
        "id": "53FDsuT2Z2_z"
      },
      "id": "53FDsuT2Z2_z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ELMODataset(Dataset):\n",
        "  def __init__(self, vectors, targets):\n",
        "    self.vectors = vectors\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.vectors)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    vector = self.vectors[idx]\n",
        "    target = self.targets[idx]\n",
        "\n",
        "    return [torch.tensor(vector), torch.tensor(target, dtype=torch.long)]"
      ],
      "metadata": {
        "id": "ngUafyIyapHJ"
      },
      "id": "ngUafyIyapHJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "trainset = ELMODataset(train_vectorized, y_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = ELMODataset(val_vectorized, y_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "ZpbSGfNvZ3C6"
      },
      "id": "ZpbSGfNvZ3C6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(elmo_clf.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "vMQh1eGwZ3E_"
      },
      "id": "vMQh1eGwZ3E_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(6):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = elmo_clf(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 20:.3f}')\n",
        "            running_loss = 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8L-26wIhbMi",
        "outputId": "15c079fa-5e74-426a-dd60-d202a6ce7e89"
      },
      "id": "i8L-26wIhbMi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   200] loss: 6.915\n",
            "[1,   400] loss: 6.854\n",
            "[1,   600] loss: 6.745\n",
            "[1,   800] loss: 6.374\n",
            "[1,  1000] loss: 5.148\n",
            "[2,   200] loss: 3.129\n",
            "[2,   400] loss: 2.997\n",
            "[2,   600] loss: 2.807\n",
            "[2,   800] loss: 2.957\n",
            "[2,  1000] loss: 2.757\n",
            "[3,   200] loss: 2.438\n",
            "[3,   400] loss: 2.098\n",
            "[3,   600] loss: 2.181\n",
            "[3,   800] loss: 2.161\n",
            "[3,  1000] loss: 2.099\n",
            "[4,   200] loss: 1.818\n",
            "[4,   400] loss: 1.675\n",
            "[4,   600] loss: 2.070\n",
            "[4,   800] loss: 2.091\n",
            "[4,  1000] loss: 2.069\n",
            "[5,   200] loss: 1.759\n",
            "[5,   400] loss: 1.594\n",
            "[5,   600] loss: 1.534\n",
            "[5,   800] loss: 1.305\n",
            "[5,  1000] loss: 1.662\n",
            "[6,   200] loss: 0.867\n",
            "[6,   400] loss: 1.348\n",
            "[6,   600] loss: 1.104\n",
            "[6,   800] loss: 1.295\n",
            "[6,  1000] loss: 1.349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = []\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    outputs = elmo_clf(inputs)\n",
        "    predicted.extend(torch.argmax(outputs, dim=1).tolist())"
      ],
      "metadata": {
        "id": "qYO9JFk4ofGB"
      },
      "id": "qYO9JFk4ofGB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = y_test\n",
        "y_pred = predicted\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NggBmET2pYAJ",
        "outputId": "959a676c-07fa-4626-f14f-31a8dd693fc3"
      },
      "id": "NggBmET2pYAJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9114198871037777"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_splitted = [title.split() for title in test_df['title']]"
      ],
      "metadata": {
        "id": "nBz79BxRxtDG"
      },
      "id": "nBz79BxRxtDG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "test_vectorized = elmo(test_splitted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hPMBoB1xcuH",
        "outputId": "bf2fac76-18ec-4674-c9cd-5a6f268cb20a"
      },
      "id": "7hPMBoB1xcuH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 20s, sys: 8.8 s, total: 3min 29s\n",
            "Wall time: 1min 48s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = ELMODataset(test_vectorized, test_df['is_fake'].values)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "07vrE4A_yczi"
      },
      "id": "07vrE4A_yczi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predicted = []\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    outputs = elmo_clf(inputs)\n",
        "    predicted.extend(torch.argmax(outputs, dim=1).tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foLxooNSzLYt",
        "outputId": "7fb26fef-c0ac-48d3-81be-604e008c3479"
      },
      "id": "foLxooNSzLYt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 522 ms, sys: 256 ms, total: 778 ms\n",
            "Wall time: 1.24 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['is_fake'] = predicted\n",
        "test_df.to_csv('/content/vvasin/elmo_predicted.tsv', index=False, sep='\\t')"
      ],
      "metadata": {
        "id": "69k5pskHziKC"
      },
      "id": "69k5pskHziKC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e9ca8dcf-f55b-45f0-9841-7434168fc550",
      "metadata": {
        "id": "e9ca8dcf-f55b-45f0-9841-7434168fc550"
      },
      "source": [
        "### BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8067d261-4dee-4324-86ee-8d33b7ca5a10",
      "metadata": {
        "id": "8067d261-4dee-4324-86ee-8d33b7ca5a10"
      },
      "outputs": [],
      "source": [
        "!pip install -r bertRequirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc5b7d0f-0164-423a-9091-3b6f4a37df16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc5b7d0f-0164-423a-9091-3b6f4a37df16",
        "outputId": "27011030-b81b-4ce4-fe21-2cd547f09b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from bert_classifier import BertClassifier\n",
        "\n",
        "classifier = BertClassifier(\n",
        "        model_path='cointegrated/rubert-tiny',\n",
        "        tokenizer_path='cointegrated/rubert-tiny',\n",
        "        n_classes=2,\n",
        "        epochs=5,\n",
        "        model_save_path='/content/bert.pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8833227-0072-4a7a-863c-a55bb61e25b1",
      "metadata": {
        "id": "f8833227-0072-4a7a-863c-a55bb61e25b1"
      },
      "outputs": [],
      "source": [
        "classifier.preparation(\n",
        "        X_train=X_train,\n",
        "        y_train=y_train,\n",
        "        X_valid=X_test,\n",
        "        y_valid=y_test\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90824ad-f207-4483-90ee-f3c42aed3031",
      "metadata": {
        "id": "b90824ad-f207-4483-90ee-f3c42aed3031",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c945c33-cd3c-4da3-b019-44f0885e0d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Train loss 0.6086610032398075 accuracy 0.8113330438558403\n",
            "Val loss 0.5664233940816403 accuracy 0.8515625\n",
            "----------\n",
            "Epoch 2/5\n",
            "Train loss 0.45336810380153286 accuracy 0.8894919669995658\n",
            "Val loss 0.6560147800638434 accuracy 0.8559027777777777\n",
            "----------\n",
            "Epoch 3/5\n",
            "Train loss 0.35123130670054403 accuracy 0.9205384281372123\n",
            "Val loss 0.7322190685178308 accuracy 0.8541666666666666\n",
            "----------\n",
            "Epoch 4/5\n",
            "Train loss 0.27132093387910833 accuracy 0.9411636995223621\n",
            "Val loss 0.7267862384517988 accuracy 0.8637152777777777\n",
            "----------\n",
            "Epoch 5/5\n",
            "Train loss 0.21875851424554246 accuracy 0.9546244029526705\n",
            "Val loss 0.7532525329388591 accuracy 0.8628472222222222\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "classifier.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "855d6080-aa8e-4176-9ecd-b9b156744f13",
      "metadata": {
        "id": "855d6080-aa8e-4176-9ecd-b9b156744f13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9998298b-87c7-418f-d545-ccad18e0ff92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 36s, sys: 9.81 s, total: 2min 46s\n",
            "Wall time: 2min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "predictions = [classifier.predict(t) for t in X_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ecba9b-9b9e-453e-8cd0-d16523e35926",
      "metadata": {
        "id": "20ecba9b-9b9e-453e-8cd0-d16523e35926",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8364d812-559a-4655-ee3f-0f7811bd4372"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8635589020076448"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "y_true = y_test\n",
        "y_pred = predictions\n",
        "f1_score(y_true, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Итоги"
      ],
      "metadata": {
        "id": "D811fAatscaT"
      },
      "id": "D811fAatscaT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Качество\n",
        "* google search 1.0 F1 score\n",
        "* TF-IDF + SGDclassifier 0.7819 F1 score \n",
        "* ELMO + MLP 0.9114 F1 score \n",
        "* tinyBERT 0.8636 F1 score <br>\n",
        "2. Время отработки на тестовых данных (на CPU)\n",
        "* google search >1 ч.\n",
        "* TF-IDF + SGDclassifier 21.2 мс\n",
        "* ELMO + MLP 3.5 минуты\n",
        "* tinyBERT 3 минуты <br>"
      ],
      "metadata": {
        "id": "U7dMAV9isfIl"
      },
      "id": "U7dMAV9isfIl"
    },
    {
      "cell_type": "code",
      "source": [
        "#Ну все, тф-идф можно в продакшн"
      ],
      "metadata": {
        "id": "UKNhsMkpYztl"
      },
      "id": "UKNhsMkpYztl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "SKBkonturTest.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6f69e7fa-c1f1-487d-a08c-27566e1dd6e7",
        "d8bd5401-356a-42dd-8cd7-d31a1c8981e9",
        "d4353824-8df0-4048-9976-d95a6334083e",
        "e9ca8dcf-f55b-45f0-9841-7434168fc550"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}